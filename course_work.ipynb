{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import pickle\n",
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "import pymorphy2\n",
    "import bs4\n",
    "import collections\n",
    "import re\n",
    "import requests\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "extended_punctuation = string.punctuation + '—»«...--\"''\" '\n",
    "from stop_words import get_stop_words\n",
    "stoplist = get_stop_words('ru') + ['сей', 'свой', 'едва', 'самый', 'го', 'час', 'часы', 'ть', 'минута', 'метр'] + ['com', 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(some_text):\n",
    "    some_text = re.sub(r'\\[|\\]|([0-9])|[a-zA-ZàâäôéèëêïîçùûüÿæœÀÂÄÔÉÈËÊÏÎŸÇÙÛÜÆŒ]', '', str(some_text))\n",
    "    lemmatized_text = [morph.parse(word)[0].normal_form for word in word_tokenize(some_text.lower()) if\n",
    "                       morph.parse(word)[0].normal_form not in stoplist and not in extended_punctuation]\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(model, feature_names, no_top_words):\n",
    "    '''\n",
    "    берет модель топик-моделинга, слова и количество топиков, возврашает темы\n",
    "    '''\n",
    "    with open('topics1929example.txt', 'w', encoding='utf-8') as f:\n",
    "        for topic_idx, topic in enumerate(model.components_):\n",
    "            print(f\"Тема {topic_idx+1}:\", file=f)\n",
    "            topic_words = \", \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
    "            print(topic_words, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from prozhitotools import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = dump.Wrapper(csvpath='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalin_notes = dw.notes[(1928, 1, 1) : (1953, 12, 31)]#отбор записей сталинского периоода\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(stalin_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = set()\n",
    "for note in stalin_notes:\n",
    "    try:\n",
    "        authors.add(note.author)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = [author.split(',') for author in authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = {author for author in authors if author}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = [author for author in authors if author]#отбор авторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors = pd.DataFrame(authors,columns=('Автор','Число записей'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes1953 = dw.notes[(1953, 1, 1) : (1953, 12, 31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(notes1953)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "authors = list(Counter(authors).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalin_notes_without_war1 = dw.notes[(1928, 1, 1) : (1941, 6, 21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalin_notes_without_war2 = dw.notes[(1945, 5, 10) : (1953, 3, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaries_for_years = [dw.notes[(year, 1, 1) : (year, 12, 31)] for year in range(1928, 1954)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaries_for_years_text = [[text.text for text in year] for year in diaries_for_years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "years_diaries_dic = {}\n",
    "for diaries, year in zip(diaries_for_years_text, range(1928, 1954)):\n",
    "    years_diaries_dic[year] = [preprocess_text(diarie) for diarie in diaries]\n",
    "    print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(years_diaries_dic[1929])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_diaries_dic_example = {'1929': [preprocess_text(diarie) for diarie in diaries_for_years_text[1]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('years_diaries_dic_example.pickle', 'wb') as fw:\n",
    "    pickle.dump(years_diaries_dic_example, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('years_diaries_clean_dic.pickle', 'wb') as fw:\n",
    "    pickle.dump(years_diaries_dic, fw, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pickle.Pickler(open('years_diaries_clean_dic.pickle',\"wb\")) \n",
    "p.fast = True \n",
    "p.dump(years_diaries_dic) # d could be your dictionary or any file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from prozhitotools import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('years_diaries_clean_dic.pickle', 'rb') as f:\n",
    "    years_diaries_dic1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('years_diaries_dic[1929].txt', 'w') as fw:\n",
    "    years_diaries_dic_w = fw.writelines(years_diaries_dic[1929])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('authors.pickle', 'wb') as fw:\n",
    "    pickle.dump(authors, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaries_for_years_text_dict = {(range(1928, 1954)): year for year in diaries_for_years_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaries_for_years = [[dw.notes[(year, 1, 1) : (year, 12, 31)] for year in range(1928, 1954)]\n",
    "for year in range(1928, 1954):\n",
    "    \n",
    "    with open(f\"Запись {i+1}\", 'w', encoding = 'utf-8') as fw:\n",
    "        fw.write(note)\n",
    "    stalin_notes_without_war1 = [[year, len(dw.notes[(year, 1, 1) : (year, 12, 31)])] for year in range(1928, 1940)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalin_notes_without_war.dump('stalin_notes_without_war.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('authors.pickle', 'wb') as fw:\n",
    "    pickle.dump(authors, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors = pd.DataFrame(authors,columns=('Автор','Число записей'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('number_of_records.csv', 'w', encoding='utf-8') as f:\n",
    "    df_authors.to_csv(f, index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = {author for author in authors if author}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_note_for_years = pd.DataFrame(note_for_years,columns=('Год','Число записей'))\n",
    "with open('note_for_years.csv', 'w', encoding='utf-8') as f:\n",
    "    df_note_for_years.to_csv(f, index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(authors)#854 автора (дневника?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from nltk import word_tokenize\n",
    "from nltk import FreqDist\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "from stop_words import get_stop_words\n",
    "stoplist = get_stop_words('ru') + get_stop_words('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_diaries_dic_example = {1929: [preprocess_text(diarie) for diarie in diaries_for_years_text[1]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stalin_notes.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemma_stalin_notes = [preprocess_text(note.text) for note in stalin_notes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_stalin_notes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, note in enumerate(lemma_stalin_notes):\n",
    "    with open(f\"Запись {i+1}\", 'w', encoding = 'utf-8') as fw:\n",
    "        fw.write(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kareev = '11, суббота. В ун[иверситетской] библ[иотеке]. Ждал Е.Г. Соколову. Приезд Жоржа. Вечером у Успенских. Письмо Васе (36) и открытка Любовичу. Письмо Е.Г. Соколовой и откр[ытка] Леночке. По рукописи, отправ[ленной] в Париж: № 839 почт[овой] росписки; а исход[ящий] Ак[адемии] наук 8814.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_text(years_diaries_dic[1929][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=5, ngram_range=(2, 2), stop_words=stoplist)\n",
    "    tfidf = tfidf_vectorizer.fit_transform(years_diaries_dic_example[1929])\n",
    "    tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "    nmf = NMF(n_components=20, random_state=42, alpha=.1, l1_ratio=.5, init='nndsvd', max_iter=100000).fit(tfidf)\n",
    "    get_topics(nmf, tfidf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(stalin_notes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ' '.join(words).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_diaries_dic_example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
